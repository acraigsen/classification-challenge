{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore', message=\"KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\")\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Data\n",
    "\n",
    "The data is located at [https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv](https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv)\n",
    "\n",
    "Dataset Source: [UCI Machine Learning Library](https://archive.ics.uci.edu/dataset/94/spambase)\n",
    "\n",
    "Import the data using Pandas. Display the resulting DataFrame to confirm the import was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  spam  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "2                      2259     1  \n",
       "3                       191     1  \n",
       "4                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv(\"https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Model Performance\n",
    "\n",
    "I expect Random Forest to perform better. Logistic Regression is a simpler linear model suitable for linear relationships, while Random Forest is a more complex ensemble model that can handle non-linear relationships and provide robust predictions in various scenarios. Random Forest is primarily for classification tasks where there are non-linear relationships between features and targets. For this reason it is often used for fraud detection, or in this case Spam detection, and so I would expect it to perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Replace the text in this markdown cell with your predictions, and be sure to provide justification for your guess.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the labels set `y` and features DataFrame `X`\n",
    "y = data['spam']\n",
    "X = data.drop(columns=['spam'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "0    2788\n",
      "1    1813\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the balance of the labels variable (`y`) by using the `value_counts` function.\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.813</td>\n",
       "      <td>494</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.319</td>\n",
       "      <td>12</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.500</td>\n",
       "      <td>186</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.307</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "1370            0.09                0.0           0.09           0.0   \n",
       "3038            0.00                0.0           0.00           0.0   \n",
       "2361            0.00                0.0           2.43           0.0   \n",
       "156             0.00                0.0           0.00           0.0   \n",
       "2526            0.00                0.0           0.00           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "1370           0.39            0.09              0.09                0.00   \n",
       "3038           0.00            0.00              0.00                0.00   \n",
       "2361           0.00            0.00              0.00                0.00   \n",
       "156            1.31            0.00              1.31                1.31   \n",
       "2526           0.00            0.00              0.00                0.00   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       "1370             0.19            0.29  ...                   0.0        0.000   \n",
       "3038             0.00            0.00  ...                   0.0        0.124   \n",
       "2361             0.27            0.00  ...                   0.0        0.000   \n",
       "156              1.31            1.31  ...                   0.0        0.000   \n",
       "2526             0.00            0.00  ...                   0.0        0.000   \n",
       "\n",
       "      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "1370        0.139          0.0        0.310        0.155          0.0   \n",
       "3038        0.124          0.0        0.000        0.000          0.0   \n",
       "2361        0.344          0.0        0.000        0.000          0.0   \n",
       "156         0.000          0.0        0.117        0.117          0.0   \n",
       "2526        0.000          0.0        0.000        0.000          0.0   \n",
       "\n",
       "      capital_run_length_average  capital_run_length_longest  \\\n",
       "1370                       6.813                         494   \n",
       "3038                       1.800                           8   \n",
       "2361                       2.319                          12   \n",
       "156                       48.500                         186   \n",
       "2526                       2.307                           8   \n",
       "\n",
       "      capital_run_length_total  \n",
       "1370                      1458  \n",
       "3038                        45  \n",
       "2361                       167  \n",
       "156                        291  \n",
       "2526                        30  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `StandardScaler` to scale the features data. Remember that only `X_train` and `X_test` DataFrames should be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "scaler.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.84417967e-02, -1.62823436e-01, -3.73283587e-01,\n",
       "        -4.43387016e-02,  1.25329068e-01, -1.75557108e-02,\n",
       "        -4.94618697e-02, -2.58223628e-01,  3.74143676e-01,\n",
       "         7.84018383e-02,  1.64169725e+00, -7.44333103e-02,\n",
       "        -3.27398098e-01,  1.51199468e+00, -1.90055678e-01,\n",
       "         7.05973261e-01,  1.15944336e-01, -3.45099898e-01,\n",
       "         6.08468580e-03,  7.83188746e+00,  7.10708263e-01,\n",
       "        -1.16300745e-01,  8.23756701e-01,  2.01038747e-01,\n",
       "        -3.26710260e-01, -3.00878899e-01, -2.30922222e-01,\n",
       "        -2.31071959e-01, -1.72682655e-01, -2.24879107e-01,\n",
       "        -1.74395864e-01, -1.43223289e-01, -1.73866411e-01,\n",
       "        -1.45765474e-01, -1.93393004e-01, -2.42335411e-01,\n",
       "        -3.30036623e-01, -5.64810168e-02, -1.78189932e-01,\n",
       "        -1.86445138e-01, -1.21635838e-01, -1.74633824e-01,\n",
       "        -2.03750279e-01, -1.27828730e-01, -2.99465798e-01,\n",
       "        -2.11088191e-01, -7.04194454e-02, -1.17147007e-01,\n",
       "        -1.57562225e-01, -8.70397336e-03, -1.73306666e-01,\n",
       "         5.29806142e-02,  3.21641987e-01, -1.22745187e-01,\n",
       "         5.10246830e-02,  2.10678454e+00,  2.08342875e+00],\n",
       "       [-3.41222369e-01, -1.62823436e-01, -5.50609354e-01,\n",
       "        -4.43387016e-02, -4.52759566e-01, -3.44393902e-01,\n",
       "        -2.97595333e-01, -2.58223628e-01, -3.19924558e-01,\n",
       "        -3.75563990e-01, -2.95841929e-01,  1.17959774e+00,\n",
       "        -3.27398098e-01, -1.76781934e-01, -1.90055678e-01,\n",
       "        -2.92764750e-01, -3.19508636e-01, -3.45099898e-01,\n",
       "        -4.84613805e-01, -1.57775726e-01, -8.31630426e-03,\n",
       "        -1.16300745e-01, -2.87897743e-01, -2.04168205e-01,\n",
       "        -3.26710260e-01, -3.00878899e-01, -2.30922222e-01,\n",
       "        -2.31071959e-01, -1.72682655e-01, -2.24879107e-01,\n",
       "        -1.74395864e-01, -1.43223289e-01, -1.73866411e-01,\n",
       "        -1.45765474e-01, -1.93393004e-01, -2.42335411e-01,\n",
       "        -3.30036623e-01, -5.64810168e-02, -1.78189932e-01,\n",
       "        -1.86445138e-01, -1.21635838e-01, -1.74633824e-01,\n",
       "         3.23710254e+00, -1.27828730e-01, -2.99465798e-01,\n",
       "        -2.11088191e-01, -7.04194454e-02, -1.17147007e-01,\n",
       "         3.45899003e-01, -6.11845118e-02, -1.73306666e-01,\n",
       "        -3.09886797e-01, -3.05752538e-01, -1.22745187e-01,\n",
       "        -1.02592159e-01, -2.13686862e-01, -4.13384669e-01],\n",
       "       [-3.41222369e-01, -1.62823436e-01,  4.23718633e+00,\n",
       "        -4.43387016e-02, -4.52759566e-01, -3.44393902e-01,\n",
       "        -2.97595333e-01, -2.58223628e-01,  6.66382932e-01,\n",
       "        -3.75563990e-01, -2.95841929e-01,  1.84081411e+00,\n",
       "        -3.27398098e-01, -1.76781934e-01, -1.90055678e-01,\n",
       "        -2.92764750e-01, -3.19508636e-01, -3.45099898e-01,\n",
       "        -7.77904856e-01, -1.57775726e-01,  6.77649662e-01,\n",
       "        -1.16300745e-01, -2.87897743e-01, -2.04168205e-01,\n",
       "        -1.68703137e-01,  3.26772026e-01, -2.30922222e-01,\n",
       "        -2.31071959e-01,  3.08115098e-01, -2.24879107e-01,\n",
       "        -1.74395864e-01, -1.43223289e-01,  2.97545655e-01,\n",
       "        -1.45765474e-01, -1.93393004e-01, -2.42335411e-01,\n",
       "        -3.30036623e-01, -5.64810168e-02, -1.78189932e-01,\n",
       "         6.50057568e-01, -1.21635838e-01, -1.74633824e-01,\n",
       "        -2.03750279e-01, -1.27828730e-01, -2.99465798e-01,\n",
       "        -2.11088191e-01, -7.04194454e-02, -1.17147007e-01,\n",
       "        -1.57562225e-01,  7.08530052e-01, -1.73306666e-01,\n",
       "        -3.09886797e-01, -3.05752538e-01, -1.22745187e-01,\n",
       "        -8.66880815e-02, -1.94588332e-01, -1.97807006e-01],\n",
       "       [-3.41222369e-01, -1.62823436e-01, -5.50609354e-01,\n",
       "        -4.43387016e-02,  1.48902533e+00, -3.44393902e-01,\n",
       "         3.31412508e+00,  2.96025836e+00,  4.46549327e+00,\n",
       "         1.67510923e+00, -2.95841929e-01, -6.21646859e-01,\n",
       "        -3.27398098e-01, -1.76781934e-01, -1.90055678e-01,\n",
       "        -2.92764750e-01,  2.68282502e+00, -3.45099898e-01,\n",
       "        -1.91322753e-01,  2.39501910e+00,  2.59504851e+00,\n",
       "        -1.16300745e-01, -2.87897743e-01, -2.04168205e-01,\n",
       "        -3.26710260e-01, -3.00878899e-01, -2.30922222e-01,\n",
       "        -2.31071959e-01, -1.72682655e-01, -2.24879107e-01,\n",
       "        -1.74395864e-01, -1.43223289e-01, -1.73866411e-01,\n",
       "        -1.45765474e-01, -1.93393004e-01, -2.42335411e-01,\n",
       "        -3.30036623e-01, -5.64810168e-02, -1.78189932e-01,\n",
       "        -1.86445138e-01, -1.21635838e-01, -1.74633824e-01,\n",
       "        -2.03750279e-01, -1.27828730e-01, -2.99465798e-01,\n",
       "        -2.11088191e-01, -7.04194454e-02, -1.17147007e-01,\n",
       "        -1.57562225e-01, -4.95023630e-01, -1.73306666e-01,\n",
       "        -1.72933613e-01,  1.67829135e-01, -1.22745187e-01,\n",
       "         1.32846839e+00,  6.36197727e-01,  2.13047160e-02],\n",
       "       [-3.41222369e-01, -1.62823436e-01, -5.50609354e-01,\n",
       "        -4.43387016e-02, -4.52759566e-01, -3.44393902e-01,\n",
       "        -2.97595333e-01, -2.58223628e-01, -3.19924558e-01,\n",
       "        -3.75563990e-01, -2.95841929e-01,  9.28791529e-01,\n",
       "        -3.27398098e-01, -1.76781934e-01, -1.90055678e-01,\n",
       "        -2.92764750e-01, -3.19508636e-01, -3.45099898e-01,\n",
       "        -1.63121690e-01, -1.57775726e-01,  3.85953999e+00,\n",
       "        -1.16300745e-01, -2.87897743e-01, -2.04168205e-01,\n",
       "        -3.26710260e-01, -3.00878899e-01,  1.64238800e-01,\n",
       "        -2.31071959e-01, -1.72682655e-01, -2.24879107e-01,\n",
       "        -1.74395864e-01, -1.43223289e-01, -1.73866411e-01,\n",
       "        -1.45765474e-01, -1.93393004e-01, -2.42335411e-01,\n",
       "        -3.30036623e-01, -5.64810168e-02, -1.78189932e-01,\n",
       "        -1.86445138e-01, -1.21635838e-01, -1.74633824e-01,\n",
       "        -2.03750279e-01, -1.27828730e-01, -2.99465798e-01,\n",
       "        -2.11088191e-01, -7.04194454e-02, -1.17147007e-01,\n",
       "        -1.57562225e-01, -4.95023630e-01, -1.73306666e-01,\n",
       "        -3.09886797e-01, -3.05752538e-01, -1.22745187e-01,\n",
       "        -8.70558058e-02, -2.13686862e-01, -4.39890119e-01]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the training data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit a Logistic Regression Model\n",
    "\n",
    "Create a Logistic Regression model, fit it to the training data, make predictions with the testing data, and print the model's accuracy score. You may choose any starting settings you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Logistic Regression model and print the model score\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "#Fit the model\n",
    "lr_model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1\n",
      " 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0\n",
      " 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1\n",
      " 0 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0\n",
      " 1 1 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0\n",
      " 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1\n",
      " 1 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0\n",
      " 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1\n",
      " 0 0 1 0 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 1 0 0\n",
      " 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Review the predictions\n",
    "print(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9196525515743756\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions`.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit a Random Forest Classifier Model\n",
    "\n",
    "Create a Random Forest Classifier model, fit it to the training data, make predictions with the testing data, and print the model's accuracy score. You may choose any starting settings you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1\n",
      " 1 0 1 1 0 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0\n",
      " 1 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0\n",
      " 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1\n",
      " 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 1 0\n",
      " 1 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0\n",
      " 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0\n",
      " 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 1 0 1\n",
      " 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0\n",
      " 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0\n",
      " 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1\n",
      " 0 0 1 0 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 0\n",
      " 1 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 1 1 1 1 1 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Review the predictions\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9554831704668838\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions`.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Models\n",
    "\n",
    "As expected the Random Forest model performed better with an accuracy of 95.55% as opposed to the Logistic regression model accuracy of 91.97%. This outcome shows the strength of using multiple decision trees to capture a broader range of data patterns in complex datasets where interactions between features play a significant role in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Replace the text in this markdown cell with your answers to these questions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
